{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d91e81-755f-4957-bfc1-a19437dd5589",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "1. Complete full game is been retireved code is done, but the column names are not accurate need to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e322a64a-04f9-488a-8066-c37d558c5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from lxml.html import fromstring\n",
    "import requests\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f3b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Functions\n",
    "\n",
    "#### Getting Proxy\n",
    "\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr'):\n",
    "        if (i.xpath('.//td[7][contains(text(),\"yes\")]')) and (i.xpath('.//td[5][contains(text(),\"elite proxy\")]')):\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b7393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FInding good_proxy\n",
    "\n",
    "def get_good_proxy():\n",
    "    proxies = get_proxies()\n",
    "    proxy_pool = cycle(proxies)\n",
    "    url = 'https://httpbin.org/ip'\n",
    "    url2 = 'https://www.google.com/maps/dir///@13.115399,77.6192442,15z/data=!4m5!4m4!1m1!4e2!1m0!3e0'\n",
    "\n",
    "    print(\"Length of Proxies List\",len(proxies))\n",
    "\n",
    "    good_Proxy = 0\n",
    "\n",
    "    for i in range(1,len(proxies)):\n",
    "        #Get a proxy from the pool\n",
    "        proxy = next(proxy_pool)\n",
    "        #print(\"Request #%d\"%i)\n",
    "        try:\n",
    "            response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy}, timeout=10)\n",
    "            #print(response.json())\n",
    "            #print(response.status_code)\n",
    "            response2 = requests.get(url2, proxies={\"http\": proxy, \"https\": proxy}, timeout=10)\n",
    "            print(response2.status_code)\n",
    "\n",
    "        except:\n",
    "            print(\"Skipping. Connnection error\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            if int(response2.status_code) == 200:\n",
    "                good_Proxy = proxy\n",
    "                print(\"Good Proxy: \", good_Proxy)\n",
    "                print(\"sucess\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Error\")\n",
    "        \n",
    "            return good_Proxy\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1db7d85-8f2c-4282-97d4-5448f5c5cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Function that returns links for all montgs where NBA took place\n",
    "\n",
    "def month_func(driver):\n",
    "    \n",
    "    month_links =[]\n",
    "    \n",
    "    ############ default range is 10 as we have 9 months (NBA games)\n",
    "    for i in range(1,10):\n",
    "        \n",
    "\n",
    "        ##### NBA Month page (links)\n",
    "        try:\n",
    "            link_xpath = '//*[@id=\"content\"]/div[2]/div[{}]/a'.format(i)\n",
    "            link = driver.find_element_by_xpath(link_xpath).get_attribute('href')\n",
    "            month_links.append(link)\n",
    "        except:\n",
    "            pass\n",
    " \n",
    "        \n",
    "    return month_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea038980-4ede-4074-8207-f073be0b5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxscore_func(driver):\n",
    "    \n",
    "    boxscore_links = []\n",
    "    \n",
    "     ##### Box Score page (links)\n",
    "    # Find all elements matching the XPath\n",
    "    boxscores_xpath = '//*[@id=\"schedule\"]/tbody//td[6]/a'\n",
    "    elements = driver.find_elements_by_xpath(boxscores_xpath)\n",
    "\n",
    "    # Extract href attributes from the elements\n",
    "    boxscore_links = [element.get_attribute('href') for element in elements]\n",
    "    \n",
    "    return boxscore_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e72be95-be8a-441b-8ed3-cf1e130dfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### New Version\n",
    "\n",
    "def read_stats(element):\n",
    "    html_content = element[0].get_attribute('outerHTML')\n",
    "    df = pd.read_html(html_content)[0]\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def get_scores(driver, BoxScore_URL):\n",
    "    driver.get(BoxScore_URL)\n",
    "    driver.implicitly_wait(10)\n",
    "    tables = driver.find_elements(By.XPATH, '//*[@id=\"div_line_score\"]//table')\n",
    "    games = []\n",
    "\n",
    "    for table in tables:\n",
    "        headers = [header.text for header in table.find_elements(By.XPATH, './/thead/tr/th')]\n",
    "        headers = [h for h in headers if h != 'Scoring']  # More safe way to remove 'Scoring'\n",
    "        \n",
    "        rows = table.find_elements(By.XPATH, './/tbody/tr')\n",
    "        data = [[data.text for data in row.find_elements(By.XPATH, './/th | .//td')] for row in rows]\n",
    "        linescore_df = pd.DataFrame(data, columns=headers)\n",
    "        linescore_df.rename(columns={'T': 'total', ' ': 'team'}, inplace=True)\n",
    "        teams = list(linescore_df['team'])\n",
    "        \n",
    "        summaries = []\n",
    "        for team in teams:\n",
    "            try:\n",
    "                basic_element = driver.find_elements(By.XPATH, f'//*[@id=\"box-{team}-game-basic\"]')\n",
    "                advanced_element = driver.find_elements(By.XPATH, f'//*[@id=\"box-{team}-game-advanced\"]')\n",
    "                basic = read_stats(basic_element)\n",
    "                advanced = read_stats(advanced_element)\n",
    "\n",
    "                # Combine stats\n",
    "                total_stats = pd.concat([basic.iloc[-1], advanced.iloc[-1]])\n",
    "                total_stats.index = [idx[1] if isinstance(idx, tuple) else idx for idx in total_stats.index]\n",
    "                total_stats.index = total_stats.index.str.lower() + '_total'\n",
    "\n",
    "                max_stats = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
    "                max_stats.index = [idx[1] if isinstance(idx, tuple) else idx for idx in max_stats.index]\n",
    "                max_stats.index = max_stats.index.str.lower() + '_max'\n",
    "\n",
    "                summary = pd.concat([total_stats, max_stats])\n",
    "                summaries.append(summary)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing team {team}: {e}\")\n",
    "                continue  # Skip to next team if error\n",
    "        \n",
    "        if summaries:\n",
    "            try:\n",
    "                summary_df = pd.concat(summaries, axis=1).T\n",
    "                summary_df.drop(columns=['bpm'], errors='ignore', inplace=True)\n",
    "                game_df = pd.concat([summary_df, linescore_df], axis=1)\n",
    "                game_df['home'] = [0, 1]\n",
    "\n",
    "                game_opp = game_df.iloc[::-1].reset_index(drop=True)\n",
    "                game_opp.columns = [f'{col}_opp' for col in game_opp.columns]\n",
    "\n",
    "                full_game = pd.concat([game_df, game_opp], axis=1)\n",
    "                full_game['date'] = pd.to_datetime(os.path.basename(BoxScore_URL)[:8], format='%Y%m%d')\n",
    "                full_game['season'] = full_game['date'].dt.year\n",
    "                full_game['won'] = full_game['total'] > full_game['total_opp']\n",
    "                full_game = full_game.loc[:, ~full_game.columns.duplicated(keep='first')]\n",
    "\n",
    "                games.append(full_game)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing game data: {e}\")\n",
    "\n",
    "    return games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ff424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59b3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "904929e4-4537-414a-ad70-6a273311bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Opening Driver\n",
    "\n",
    "def open_driver(year):\n",
    "    PROXY = get_good_proxy()\n",
    "    webdriver.DesiredCapabilities.CHROME['proxy'] = {\n",
    "        \"httpProxy\": PROXY,\n",
    "        \"ftpProxy\": PROXY,\n",
    "        \"sslProxy\": PROXY,\n",
    "\n",
    "        \"proxyType\": \"MANUAL\",\n",
    "\n",
    "    }\n",
    "\n",
    "    # object of Options class\n",
    "    op = Options()\n",
    "    op.headless = True ## opening chrome in background\n",
    "\n",
    "    #### Old method\n",
    "#     # set chromedriver.exe path\n",
    "#     driver = webdriver.Chrome(options=op)\n",
    "#     driver.maximize_window()\n",
    "#     sleep(2)\n",
    "    \n",
    "    #### New Way\n",
    "    driver = webdriver.Chrome(\"chromedriver-win64\\chromedriver.exe\", options=op)\n",
    "    driver.maximize_window()\n",
    "    sleep(2)\n",
    "    \n",
    "    \n",
    "    BasketBallReferenceLink = 'https://www.basketball-reference.com/leagues/NBA_{0}_games.html'.format(year)\n",
    "    driver.get(BasketBallReferenceLink)\n",
    "    sleep(3)\n",
    "    \n",
    "    ## Calling Month_func\n",
    "    month_links = month_func(driver)\n",
    "    \n",
    "    ## Calling Boxscore_func\n",
    "    boxscore_links_list = []\n",
    "    for month_link in month_links:\n",
    "        driver.get(month_link)\n",
    "        sleep(3)\n",
    "        boxscore_links = boxscore_func(driver)\n",
    "        boxscore_links_list.append(boxscore_links)\n",
    "    \n",
    "    \n",
    "    ######## LineScores data \n",
    "    linescore_df_list = []\n",
    "    ## BoxScore_URL_list_of_list = [['https://www.basketball-reference.com/boxscores/202012220BRK.html','https://www.basketball-reference.com/boxscores/202203280CHO.html']]\n",
    "    BoxScore_URL_list_of_list = boxscore_links_list\n",
    "    \n",
    "    ### Counter\n",
    "    counter = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    for BoxScore_URL_list in BoxScore_URL_list_of_list:\n",
    "        print(\"Length of list: \", len(BoxScore_URL_list))\n",
    "            \n",
    "        for BoxScore_URL in BoxScore_URL_list:\n",
    "            \n",
    "            \n",
    "            # Increment the counter\n",
    "            counter += 1\n",
    "            \n",
    "            ## print(str(BoxScore_URL))\n",
    "\n",
    "            driver.get(str(BoxScore_URL))\n",
    "            sleep(3)\n",
    "            linescore_df = get_scores(driver, BoxScore_URL)\n",
    "            linescore_df_list.append(linescore_df)\n",
    "            \n",
    "            # Check if the counter is at a multiple of 50\n",
    "            if counter % 50 == 0:\n",
    "                print(f\"{counter} links are saved\")\n",
    "        \n",
    "    print(\"Hello world\")\n",
    "    # close browser after our manipulations\n",
    "    driver.close()\n",
    "    \n",
    "    ## return month_links,BoxScore_URL_list_of_list,linescore_df_list\n",
    "    return linescore_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d3a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Time of Mini_data = 07:59:20\n",
      "Season - 2017\n",
      "start Time of Mini_data = 07:59:20\n",
      "Length of Proxies List 20\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "Skipping. Connnection error\n",
      "200\n",
      "Good Proxy:  189.240.60.166:9090\n",
      "sucess\n",
      "Length of list:  45\n",
      "Length of list:  229\n",
      "50 links are saved\n",
      "100 links are saved\n",
      "150 links are saved\n",
      "200 links are saved\n",
      "250 links are saved\n",
      "Length of list:  232\n",
      "300 links are saved\n",
      "350 links are saved\n",
      "400 links are saved\n",
      "450 links are saved\n",
      "500 links are saved\n",
      "Length of list:  223\n",
      "550 links are saved\n",
      "600 links are saved\n",
      "650 links are saved\n",
      "700 links are saved\n",
      "Length of list:  165\n",
      "750 links are saved\n",
      "800 links are saved\n",
      "850 links are saved\n",
      "Length of list:  241\n",
      "900 links are saved\n",
      "950 links are saved\n",
      "1000 links are saved\n",
      "1050 links are saved\n",
      "1100 links are saved\n",
      "Length of list:  140\n",
      "1150 links are saved\n",
      "1200 links are saved\n",
      "1250 links are saved\n",
      "Length of list:  29\n",
      "1300 links are saved\n",
      "Length of list:  5\n",
      "Hello world\n",
      "dataframes_list_season-2017.pkl saved\n",
      "End Time  =  11:34:23\n"
     ]
    }
   ],
   "source": [
    "## Seasons\n",
    "\n",
    "## season = [2018,2019,2020,2021,2022,2023]\n",
    "\n",
    "season = [2017]\n",
    "\n",
    "\n",
    "## Create a list with the length of 'season'\n",
    "len_of_season = list(range(len(season)))\n",
    "\n",
    "\n",
    "combined_df_list = []\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "start_now = datetime.now()\n",
    "start_time = start_now.strftime(\"%H:%M:%S\")\n",
    "print(\"start Time of Mini_data =\", start_time)\n",
    "    \n",
    "\n",
    "for i,j in zip(season, len_of_season):\n",
    "    \n",
    "    print(\"Season - {0}\".format(i))\n",
    "    start_now = datetime.now()\n",
    "    start_time = start_now.strftime(\"%H:%M:%S\")\n",
    "    print(\"start Time of Mini_data =\", start_time)\n",
    "    \n",
    "\n",
    "    combined_dataframes = open_driver(i)\n",
    "    \n",
    "    # Assume complete_dfs is your list of lists of DataFrames\n",
    "    flattened_list_of_dfs = [df for sublist in combined_dataframes for df in sublist]\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(flattened_list_of_dfs, ignore_index=True)\n",
    "\n",
    "    combined_df_list.append(combined_df)\n",
    "    \n",
    "    #### Save the list of DataFrames to a pickle file\n",
    "    with open('dataframes_list_season_-{0}.pkl'.format(i), 'wb') as file:\n",
    "        pickle.dump(combined_df, file)\n",
    "        \n",
    "    print('dataframes_list_season-{0}.pkl saved'.format(i))\n",
    "\n",
    "end_now = datetime.now()\n",
    "end_time = end_now.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time  = \", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de50e8-a192-4e99-84ae-5b37cd784b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93a3dc-987d-4ca3-893b-c692922c155a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f473a88-b396-4b50-9fd8-24d342d3b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Need to extract line scores, Basic Box Score Stats & Advanced Box Score Stats (In Starts consider only summaries of the match) (For home & away always 1st team standing is away team.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cc610-64a9-4b06-aa55-b8b10ebc590b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b263f33-7578-47de-9115-16aa05947dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
