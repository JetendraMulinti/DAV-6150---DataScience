{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "\n",
    "### Reading and drop na columns\n",
    "file_names = ['dataframes_list_season_-2017.pkl',\n",
    "              'dataframes_list_season_-2018.pkl', 'dataframes_list_season_-2019.pkl',\n",
    "              'dataframes_list_season_-2020.pkl', 'dataframes_list_season_-2021.pkl',\n",
    "              'dataframes_list_season_-2022.pkl','dataframes_list_season_-2023.pkl']\n",
    "\n",
    "all_cleaned_dataframes = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    try:\n",
    "        with open(\"Data/\"+file_name, 'rb') as file:\n",
    "            # Load the dataframe from pickle file\n",
    "            dataframe = pickle.load(file)\n",
    "\n",
    "            # Filter out columns that start with 'Unnamed:'\n",
    "            dataframe = dataframe.loc[:, ~dataframe.columns.str.startswith('Unnamed:')]\n",
    "\n",
    "            # Drop all columns that are entirely NA\n",
    "            dataframe = dataframe.dropna(axis=1, how='all')\n",
    "\n",
    "            # Add the cleaned dataframe to the list\n",
    "            all_cleaned_dataframes.append(dataframe)\n",
    "            \n",
    "            ## print(f\"Processed {file_name}, columns: {dataframe.columns}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "df = pd.concat(all_cleaned_dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "### delete some more columns\n",
    "columns_to_delete = ['OT', 'OT_opp', '2OT', '3OT', '2OT_opp', '3OT_opp', '4OT', '4OT_opp',\n",
    "                    'mp_total_opp','bpm_max','bpm_max_opp']\n",
    "\n",
    "# Drop the specified columns from the dataframe\n",
    "df.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "#### rename columns\n",
    "df.rename(columns = {'mp_total':'mp'}, inplace=True)\n",
    "\n",
    "print(\"data shape:\", df.shape)\n",
    "\n",
    "columns_format = list(df.columns)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['+/-_max'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['+/-_max_opp'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083779e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Abbrivate the Team names\n",
    "##### Abbrivate the Team names\n",
    "team_df = pd.read_csv('https://raw.githubusercontent.com/JetendraMulinti/DAV-6150---DataScience/main/FinalProject-NBA_Prediction/Data/Team_full-forms.csv')\n",
    "team_df['team'] = team_df['team'].str.strip()\n",
    "team_df['team1'] = team_df['team1'].str.strip()\n",
    "\n",
    "\n",
    "##### Merge and delete the columns\n",
    "df = pd.merge(team_df, df, on = ['team'], how='inner')\n",
    "del df['team']\n",
    "df.rename(columns = {'team1':'team'}, inplace=True)\n",
    "\n",
    "team_df.rename(columns = {'team':'team_opp'}, inplace=True)\n",
    "df = pd.merge(team_df, df, on = ['team_opp'], how='inner')\n",
    "del df['team_opp']\n",
    "df.rename(columns = {'team1':'team_opp'}, inplace=True)\n",
    "\n",
    "print(\"data shape:\", df.shape)\n",
    "\n",
    "df = df[columns_format]\n",
    "\n",
    "## ordering with date\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.sort_values(by = ['date'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69ab03",
   "metadata": {},
   "source": [
    "1. We will create a target column (needs to be created on team level) -> represents the next game outcome. (Won column indicates the current match, target column indicates next match)\n",
    "\n",
    "2. Replace the Null values in Target column with “2”, False (Loss) = 0, True (Won) = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(team):\n",
    "    team['target'] = team['won'].shift(-1)\n",
    "    return team\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(add_target)\n",
    "\n",
    "## Preprocessing Target column (Null = 2, True = 1, False = 0)\n",
    "\n",
    "df['target'][pd.isnull(df['target'])] = 2\n",
    "df['target'] = df['target'].astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68386cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking the data is balance / Imbalanced\n",
    "\n",
    "df['won'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded602c",
   "metadata": {},
   "source": [
    "Checking Null values and dropping columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07971fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking null values\n",
    "\n",
    "null_columns = df.isnull().sum()\n",
    "null_columns[null_columns > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete some more columns\n",
    "more_columns_to_delete = ['index_opp']\n",
    "\n",
    "# Drop the specified columns from the dataframe\n",
    "df.drop(columns=more_columns_to_delete, inplace=True)\n",
    "\n",
    "## as we have only 1 null row (match) we will drop it\n",
    "df = df.dropna()\n",
    "\n",
    "null_columns = df.isnull().sum()\n",
    "null_columns[null_columns > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## re-ordering on date\n",
    "\n",
    "## ordering with date\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.sort_values(by = ['date'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(\"data shape:\", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d771fe",
   "metadata": {},
   "source": [
    "1. we are using TimeSeriesSplit as we need to split as dates only\n",
    "2. reason: we don't want to split the old and new data in mix, we want only historic data to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af217e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "rr = RidgeClassifier(alpha=1)\n",
    "\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "sfs = SequentialFeatureSelector(rr, \n",
    "                                n_features_to_select=40, \n",
    "                                direction=\"backward\",\n",
    "                                cv=split,\n",
    "                                n_jobs=1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "\n",
    "object_columns = df[selected_columns].select_dtypes(include='object').columns\n",
    "\n",
    "object_columns = df[selected_columns].select_dtypes(include='object').columns\n",
    "\n",
    "# Convert these object type columns to integers\n",
    "## 1\t2\t3\t4\ttotal\t1_opp\t2_opp\t3_opp\t4_opp\ttotal_opp columns\n",
    "for column in object_columns:\n",
    "    df[column] = df[column].astype(int)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fc720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[selected_columns].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_columns] = scaler.fit_transform(df[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc32476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string_S = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "print(\"Started at = \", dt_string_S)\n",
    "\n",
    "\n",
    "sfs.fit(df[selected_columns], df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd701483",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(selected_columns[sfs.get_support()])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3f762",
   "metadata": {},
   "source": [
    "1. backtest function helps to split the data according to seasons, to make sure we use atleast last 2 seasons of games to predict the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data, model, predictors, start=2, step=1):\n",
    "    all_predictions = []\n",
    "    \n",
    "    seasons = sorted(data[\"season\"].unique())\n",
    "    \n",
    "    for i in range(start, len(seasons), step):\n",
    "        season = seasons[i]\n",
    "        train = data[data[\"season\"] < season] ## Previous season\n",
    "        test = data[data[\"season\"] == season] ## Current season\n",
    "        \n",
    "        model.fit(train[predictors], train[\"target\"])\n",
    "        \n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds, index=test.index)\n",
    "        combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "        combined.columns = [\"actual\", \"prediction\"]\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91013b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(df, rr, predictors)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e74eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## removing unpredicted matches\n",
    "predictions = predictions[predictions['actual'] != 2]\n",
    "print(\"Accuracy Score: \",accuracy_score(predictions[\"actual\"], predictions[\"prediction\"]))\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string_E = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "print(\"Ended at = \", dt_string_E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b34ac3",
   "metadata": {},
   "source": [
    "Checking home ground emotion to check with our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"home\"]).apply(lambda x: x[x[\"won\"] == 1].shape[0] / x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590975a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"team\", \"season\"])['date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc22354",
   "metadata": {},
   "source": [
    "1. Here instead of predicting just using previous match we are trying to do it with last 10 matches\n",
    "2. team.rolling(10).mean() -> Finding avg of last 10 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bf603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling = df[list(selected_columns) + [\"won\", \"team\", \"season\"]]\n",
    "\n",
    "def find_team_averages(team):\n",
    "    rolling = team.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "df_rolling = df_rolling.groupby([\"team\", \"season\"], group_keys=False).apply(find_team_averages)\n",
    "\n",
    "df_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d41589",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_cols = [f\"{col}_10\" for col in df_rolling.columns]\n",
    "df_rolling.columns = rolling_cols\n",
    "df = pd.concat([df, df_rolling], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"df shape: \",df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8687f",
   "metadata": {},
   "source": [
    "Giving the prior information to modelling which we will be knowing before the start of the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "df[\"home_next\"] = add_col(df, \"home\")\n",
    "df[\"team_opp_next\"] = add_col(df, \"team_opp\")\n",
    "df[\"date_next\"] = add_col(df, \"date\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62819fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df.merge(df[rolling_cols + [\"team_opp_next\", \"date_next\", \"team\"]], left_on=[\"team\", \"date_next\"], right_on=[\"team_opp_next\", \"date_next\"])\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df01f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full[[\"team_x\", \"team_opp_next_x\", \"team_y\", \"team_opp_next_y\", \"date_next\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + removed_columns\n",
    "removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string_S = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "print(\"Started at = \", dt_string_S)\n",
    "\n",
    "sfs.fit(full[selected_columns], full[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d051a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = list(selected_columns[sfs.get_support()])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full, rr, predictors)\n",
    "\n",
    "## removing unpredicted matches\n",
    "predictions = predictions[predictions['actual'] != 2]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba874b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Accuracy Score: \",accuracy_score(predictions[\"actual\"], predictions[\"prediction\"]) * 100)\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string_E = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "print(\"Ended at = \", dt_string_E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74096f53",
   "metadata": {},
   "source": [
    "1. last 2 seasons backtest + 10 rolling (30 Features forward) accuracy: 54 % \n",
    "2. last 2 seasons backtest + 15 rolling (30 Features forward) accuracy: 53.7 % \n",
    "3. last 2 seasons backtest + 5 rolling (30 Features forward) accuracy: 52.8 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a774a",
   "metadata": {},
   "source": [
    "Improving model:\n",
    "1. try powerful model\n",
    "2. no of features & try backward method\n",
    "3. Try rolling mean (with different combinations)\n",
    "4. Make sure no null matches (before full dataframe or get only till last season and try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c804464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
